{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5TXYoBm6n6n5"
   },
   "source": [
    "# Classifier evaluation\n",
    "\n",
    "In the last two sessions, we implemented our first prediction models (T05: linear and logistic regression, T06: decision trees) -- hurray! We already separated the dataset features from their class, fed these features to a regression model or decision tree and trained the model to make a prediction, whether a patient is ill or not.\n",
    "\n",
    "We can say that we model described the existing data to a good extent (if we hadn't restricted the `max_depth` of the tree, our model would yield to a 100% accuracy). But did our algorithm actually \"learn\" anything? In other words, would our linear/tree model predict the class correctly if we give it a completely new patient and his or her health records? We don't know yet.\n",
    "\n",
    "We trained and tested our decision tree model's accuracy on the same data for a simplicity reason, but that's not usually the case in real machine learning projects. Usually, we want to create algorithms that generalize beyond the observed data. It makes sense that we could only evaluate the ability of the model to generalize from a data sample using data that it had not seen before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test split\n",
    "\n",
    "Now we understand that we would want some additional, unseen before data entries to test our prediction model, but where do we get them? Well, meaningful data collection is hard, so why don't we just say from the beginning that we preserve some part of the existing dataset and use it later for evaluation purpose. Sounds good, right?\n",
    "\n",
    "Splitting your dataset is essential for an unbiased evaluation of prediction performance. In most cases, itâ€™s enough to split your dataset randomly into two subsets:\n",
    "\n",
    "1.   The *training set* is applied to train, or fit, your model.\n",
    "2.   The *test set* is needed for an unbiased evaluation of the final model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ErnGlWaLxA1L"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preparation (from last session)\n",
    "\n",
    "df = pd.read_csv('data/data_banknote_authentication.txt', names=['Variance', 'Skewness', 'Kurtosis', 'Entropy', 'Class'])\n",
    "\n",
    "print(df.shape)\n",
    "print(df.columns)\n",
    "\n",
    "# separate target (dependent) variable from features (independent variables)\n",
    "X = df.drop('Class', axis=1).copy()\n",
    "y = df['Class'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z5-hG62phZYJ"
   },
   "source": [
    "**Recap:** If you are curious how these features were extracted from photos of the banknotes, check the [Wavelet transform](https://towardsdatascience.com/what-is-wavelet-and-how-we-use-it-for-data-science-d19427699cef) out. But simply speaking we convert each image into a distribution of its pixels and extract some statistics about the distribution:\n",
    "\n",
    "*  Variance - measure of variability or spread of the distribution;\n",
    "*   Skewness - measure of symmetry of a distribution. In normal distributions skewness = 0. Distribution skewed to the right  (a.k.a positive skewed) will have a longer right tail and to the left (negative skew) a longer left tail (longer tails occur because of outliers);\n",
    "*   Kurtosis - measures how \"thick\" are the tails of the distribution;\n",
    "* Entropy - measure of uncertainty.\n",
    "\n",
    "But don't get confused by the features - that's not the important thing in this exercise.\n",
    "\n",
    "We also have a fifth column `Class`. That looks like the target, that we want to predict. Indeed, class 1 stands for \"genuine banknote\" and class 0 for \"fake banknote\".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WrODTBE35VMz"
   },
   "source": [
    "### Exercise: Make a training and test data split (see T05)\n",
    "\n",
    "While training the logistic regression model in T05, we already made a training and test data split. Please apply this step here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "id": "4qOwuA4f6YTu",
    "outputId": "5920ceed-bdd5-449e-8a03-a011d7321de2"
   },
   "outputs": [],
   "source": [
    "# todo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fGUJzZIbEkWH"
   },
   "source": [
    "### Exercise: Evaluating the Algorithm\n",
    "Now, train a decision tree model on the training data and evaluate it using test data. Obtain a confusion matrix and compute performance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PUWqkWPYECO0"
   },
   "outputs": [],
   "source": [
    "# todo "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
